\documentclass[pdftex,11pt,a4paper]{report} 

% Document settings

\usepackage{fullpage}
\usepackage{cite}
\usepackage{datetime} 
\usepackage{geometry}
\usepackage[pdftex]{graphicx}
\usepackage{verbatim}
\usepackage{todonotes}

\geometry{verbose,lmargin=3cm,rmargin=3cm}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\begin{document}

%--------------------------------------------------------------------------------

% Title page of report

\input{./report4_title.tex}

%--------------------------------------------------------------------------------

\begin{abstract}

In this project we created a negotiation-capable AI framework for the
game of 'Diplomacy'. On the tactics-side a pattern-weight learning
algorithm \cite{Shapiro02} coupled with a best-first search strategy
finder is used. In addition a DAIDE-conforming \cite{DaideWeb}
subsystem comprising GUI client and server was implemented. To our
knowledge our server is the first implementation using the functional
language Haskell. Finally we conducted various games of humans against
AI bots to estimate the playing strength of our bot. We are optimistic
that our findings can be related to the general research field of
\textit{Automated negotiation}. Our GUI client is novel in the way
that it can be deployed as a native application, web and smart-phone.

\end{abstract}

\setcounter{tocdepth}{2} % Set the depth of toc indexing

\tableofcontents

\pagebreak

%--------------------------------------------------------------------------------

% Set arabic numbering for auto-indexing

\renewcommand*\thesection{\arabic{section}}

\section{Acknowledgements}

We thank our supervisor Dr. Iain Philipps (iccp@doc.ic.ac.uk) for his
support and guidance throughout the duration of the project. For the
software engineering aspects of the project Robert Chatley's course
'Software Engineering Methods' was very instructive, improving our
process and team collaboration. \\

Also we would like to direct our thanks at the whole DAIDE community
giving us an environment to test our AI bots. \\

The programming languages that were used for server and GUI client
have come a long way in recent years. Without the dedication of the
\textit{Haskell} and \textit{HaXe} communities to provide easy-to-use
libraries it would not have been possible to make progress on 
several fronts at the same time.

%--------------------------------------------------------------------------------

\section{Group members} 
Luke Tomlin (Team leader) \\ 
Luca Deltodesco ld509@doc.ic.ac.uk \\ 
Matthias Hueser mh2308@doc.ic.ac.uk \\
Andras Slemmer as13609@doc.ic.ac.uk \\
Cliff Sun chs09@doc.ic.ac.uk \\

%--------------------------------------------------------------------------------

\pagebreak

\chapter{Introduction}

\section{Automated negotiation}

Automated negotiation is a field of increasing interest in political
strategy, psychology and economics. At the small scale each human is
concerned with negotiation: from families to businesses one can always
discern the common pattern of autonomous agents trying to reach some
joint goal.  Another instance of \textit{cooperating agents} have been
studied recently in the field of \textit{Distributed artificial
  intelligence}: Grosz et al looked at ``Collaborative plans for
complex group activities'' \cite{Grosz96} whereas issues of
consensus-finding has been a focus of \textit{Distributed computing}
for a long time. \\

The military applications of ``Automated negotiation'' generally
assume a number of \textit{non-cooperating} agents playing an
\textit{adversial game}. The field of classical game-theory grew out
of the need to analyze such situations.  While successful it is
doubted whether its premise of purely rational entities can be
justified in reality. It is universally accepted that a lot of actions
are driven by irrational instincts rather than deliberate
planning. The question remains whether ``Automated negotiation''
theory should try to imitate humans or overcome their alleged
``weaknesses''. If the first approach is taken issues of
\textit{Emotion modelling} and \textit{Relationship inference} need to
be addressed and a proper representation found. \\

Interesting questions we would like to answer with our project are:

\begin{itemize}

\item Is a negotiating bot imitating human strategies or does 
      learning bring new techniques to the surface?

\item What is the merit of negotiating? In other words what 
      are the relative utilities of the rational and emotional
      component of our bot?

\item What relationships between negotiation bots will ensue 
      if they are left to themselves? Does chaos set in?

\end{itemize}

\section{Diplomacy and negotiation}

In this context the \textit{Game of Diplomacy} is an ideal test-bed to
explore various paradigms of ``Automated negotiation''. This is
because a number of its features can be directly related to the
complex, unpredictable domains encountered in reality:

\paragraph{Zero-sum property}
A game is said to be \textit{zero-sum} if one's player gains are
another player's losses. This is clearly the case in Diplomacy where
an advance into a favourable board position inevitably results in a
another power's unit being dislodged from this position. In reality
resource- or military conflicts behave in the same way.

\paragraph{Imperfect information}
There are two levels of uncertainty in Diplomacy: On the one hand all
move orders are written down secretly and then revealed simultaneously
during the move resolution phase. So a power has no way to plan with
the moves of its opponents but instead has to resort to ``move
prediction''. It is obvious that almost every adversial game
encountered in reality shares this property. Negotiation itself is
another layer of uncertainty in Diplomacy: messages are normally not
posted publicly and hence no player can know in advance which
strategies its opponents discussing.

\paragraph{Free-form negotiation}
In the original board-game human players are allowed to exchanged
arbitrary messages during the negotiation period. These typically
include: move-suggestions, mid-term strategies, alliance / war
declarations, accusations and rumours. Since general negotiation
in natural language requires language parsing, early 
bots \cite{Kraus92} restricted the set of possible messages to 
a formal languages. DAIDE categorizes negotation messages 
into press levels \cite{DAIDEsyntax10} from 0 (no-press) to 120.
Some examples are given in the section on DAIDE.

\paragraph{Simultaneous movements} 
Simultaneous moves are an important element of Diplomacy's game-play
and contrast with classical turn-based games like Chess or
Backgammon. They give the game a dynamic, real-time flavour -- in
reality actions happen -- if not all at once but certainly not in a
pre-determined turn order.

\paragraph{Deterministic operators}
Apart from the initial assignments of players to powers there is no
element of chance in Diplomacy. In reality many domains can be
modelled in this way once a bot has compiled its ground rules in a
knowledge base.

\subsection{Rationale of negotiation}

Negotiation is integral to the game-experience of Diplomacy. Consider
a solitary power trying to open several war-fronts at the same
time. This strategy is bound for doom because the other negotiating
agents will quickly forge a coalition against the loner. One of the
first negotiation bot for Diplomacy, the Israeli diplomat \cite{Kraus89}
reportedly fared very well against human players and is still a 
benchmark today.

\pagebreak

\section{DAIDE framework}

There is a thriving internet-based community around the Game of
Diplomacy \cite{DipArchive04} \cite{DipPouch04}. A welcome effect is
that amateur players have access to a rich body of strategic knowledge
which forms the basis of many existing bots. Until the 90s bot
development has been ad-hoc and it has been difficult to find a common
platform to validate their playing strength. To remedy this the DAIDE
framework \cite{Daide04} has been created: It comprises a language
specification for client-server interaction \cite{DAIDEsyntax10} \&
negotiation and various useful too. For detailed explanation of the 
DAIDE presslevels refer to the reference above.

\begin{itemize}

\item The \textit{DAIDE Server} enables both human and AI players to
      compete in a game. A screenshot of the Main GUI is given below:

\item \textit{DAIDE Mapper} is a server hook-in to visualize
      the game state.

\end{itemize}


%--------------------------------------------------------------------------------

\pagebreak

\chapter{The game of Diplomacy}

Only the concepts of the game necessary to understand the 
algorithms of the AI / negotiation are described here. For a
definitive reference of the game rules refer to \cite{DiploRules00}.

\section{Overview}

The Game of Diplomacy is a round-based multiplayer strategy-game set
in WWI Europe. It was conceived by Alan Callhamer in 1954. Besides
the joy it has brought to players he designed it to see how 
secret negotiations affect strategy games. Each player controls a 
European power which initially operates from a set of supply centers.
The objective of the game is to control the majority of supply-centers
on the map, using army movements to conquer new bases and ultimately
eliminate all opponents from the map. There are alternative winning
and draw conditions -- such as a simple majority after a time limit -- 
but we have not considered them in our project.

\paragraph{Game elements}

The game board consists of 73 provinces. Half of them are 
called \textit{supply centres}.

\paragraph{Provinces}

There are three type of provinces: Water, land and coastal 
provinces. In general the adjacencies of provinces are obvious
from the game map; in some intricate cases the rulebook needs to
be consulted. Each province can optionally be occupied by one
unit of the correct type. At the beginning of the game all powers
control 3 supply centres, Russia controls 4 to offset its
otherwise weak position.

\paragraph{Supply centres}

A subset of the land provinces are supply centres which can be 
occupied by a power's unit. At the end of the season each power
can build additional units in its non-occupied supply-centres.
This happens in the context of an important constraint: A power 
can never more units than supply centres controlled at the end
of each year. Both are reconciled in the build / retreat phases
at the end of each year: If there is an overhead of units they
have to be dislodged.

\paragraph{Units}

There are two type of units -- Armies and fleets -- controlled
by a power. Each can only move to provinces of the correct type.
Fleets can occupy water and coastal provinces, whereas armies 
move on land.

\section{Game turns / phases}

A game is divived into a number of turns, which is either a
\textit{fall turn} or a \textit{spring turn}. Two turns comprise
a year, the first one being 1901. Each turn contains a number of 
\textit{phases} in which the players negotiate, formulate
their orders and submit them to the server. The order of action in
fall and spring terms are the same, except that only the fall term
has a \textit{gaining-and-losing} phase.

\paragraph{1. Diplomacy phase}
In this phase players jointly devise strategies, forge alliances and
suggest move orders for the next round. Conversations can be 
one-to-one or in groups. None of the agreements
reached are binding and can even be used to deliberately 
mislead another player and prepare a back-stab. Lastly it is possible
to broadcast announcements to all players.

\paragraph{2. Order writing phase}
Afterwards each player writes down orders for its units and prepares
them for submission for the game server. There is no communication 
between players in this phase. 

\paragraph{3. Order resolution phase}
At this stage all orders are simultaneously revealed to the server,
who announces them publicly. Now the effects of the moves on the
map state are determined, resolving them according to the game rules.
In simple cases only standoffs between different move orders need
to be considered but the complex game rules result in many special
cases that need to be considered by the server. 

\paragraph{4. Retreat and Disbanding phase}
The effects of the submitted orders might make it necessary to retreat
some units from its current provinces. The only choice given to a
players is the destination province of a retreat which needs to
adjacent to the province from which the unit has been dislodged. Once
these are selected a set of \textit{retreat} orders is created and
resolved immediately by the server. As for ordinary moves standoffs
between retreat orders can occur; in this case each unit involved in
such a standoff is immediately \textit{disbanded} from the map. The
same happens if a player does not give a destination for a unit that
has to retreat.

\paragraph{5. Gaining and Losing phase (Winter)}
As mentioned initially this phase only occurs in a \textit{fall turn}.
The purpose of this phase is to adjust the number of units of a power
to the number of supply centres it controls, reflecting its current
strength. Players can submit build and disband orders as explained
below. 

\section{Order submission}

The submission of orders happens \textit{simultaneously}; the game
rules also stipulate that all orders are publicly announced. The diplomacy
phase of a game turn allows powers to signal their actual intention or
mislead other powers about them. In addition to revealing their move
orders powers can also forge alliances and devise strategies
collectively. Ultimately there is no limit to the scope of negotation
messages.

\section{Order types}

In the \textit{order writing} phase each power can optionally submit
an order for each unit controlled. Not specifying an order for a 
unit is interpreted as a \textit{hold order}. 

\paragraph{Hold order}
A unit receiving a hold order does nothing and keeps a unit on its 
current location. 

\paragraph{Move or attack order} 
Move orders shift units from their original position to one of its
adjacent provinces. A move can either be successful, result in a
standoff or fail because of insufficient strength. 

\begin{figure}
\includegraphics[scale=0.75]{./screenshots/Move0.png} \\[1cm] 

The red arrows indicate that the move order succeeded and the units
will be moved to the destination. In general a move order succeeds
if the attacking party has higher strength than the defense. Each 
support order increases the strength of offense / defense by 1.

\end{figure}

\begin{figure}
\includegraphics[scale=0.75]{./screenshots/BouncedMove.png} \\[1cm] 
The dark-red arrows indicate that the move bounced and the units will
remain in the same place. This is because both units are attempting 
to move to the same location and have the same strength, none being
supported by another unit.
\end{figure}

\paragraph{Support order}
A support order assists another unit's move or hold order. It can
either be used defensively to protect a province against an attack
order or increase the odds of another unit conquering a province.

\begin{figure}
\includegraphics[scale=0.75]{./screenshots/DefRetreat0.png} \\[1cm] 
Here the French unit at Marseille is supporting the move of it's
comrade at Gascony to Burgundy. The German unit at Burgundy was
attempting to support the move of it's ally at Parise to Gascony. In
the end it's support was cut by a dislodgement from the French
unit. After the moves are resolved, the Burgundy unit will be
dislodged at the white marker and forced to attempt a retreat in the
next phase.
\end{figure}

\paragraph{Convoy order}
This order type is restricted to fleet units. They allow to transport
an allied army between two coastal provinces across the water. In general
such convoys can be chained: If an army tries to move along a path of
several water provinces all of those need to be \textit{convoyed} 
by a fleet.

\paragraph{Retreat order}
A retreat order normally only occurs in the retreat / disband phases of the
fall and spring terms. If a unit is overpowered by an attack on its
province it needs to move to an adjacent province. The exact destination
is specified by the player in a retreat order.

\begin{figure}
\includegraphics[scale=0.75]{./screenshots/DefRetreat2.png} \\[1cm] 
Here the German unit previously dislodged from Burgundy has
succesfully retreated to Picardy.  It is possible although quite rare
for a retreat order to fail (Perhaps due to two dislodged units
attempting to retreat to the same space) and in such case the unit
would be removed from the map.
\end{figure}

\paragraph{Disband order}
If a unit cannot perform a retreat then the unit is removed from the
map automatically.

\includegraphics[scale=0.75]{./screenshots/ImmRetreat0.png} \\[1cm] 

\paragraph{Build order}
This order is limited to the \textit{Gaining and losing phase} where
unit numbers are reconciled with supply centre control. At the end of
each year the server signals the maximum number of units a player can
have in the following turn. Empty supply centres can now be used to
build any surplus units.

\paragraph{Remove order}
Any surplus units that do not have a ``supporting supply centre have
to be removed at the end of the year. With \textit{Remove orders} the
player can select which units should be removed from the board.

%--------------------------------------------------------------------------------

\pagebreak

\section{Related work}

\subsection{Existing negotiation bots}

There exist both open-course and closed-source
bots for Diplomacy. For our experiments we used only DAIDE
compatible bots but want to present some of the paradigms
used in the past:

\paragraph{Diplomat by Kraus et al}

Kraus et al used the multi-agent paradigm to implement the first
Diplomacy bot capable of negotiation \cite{Kraus95}. Their bot
comprises a collection of local agents that are dynamically bound to
different negotiation modules. In analogy to a government they define
a 'Prime Minister', 'Ministry of Defense', 'Foreign office',
'Headquarters' and 'Intelligence' which deal with arbitration,
creating DAIDE messages, long-term strategy formulation and so
forth. Hereby the 'Prime minister' fixes the character traits of the
bot. To maintain information about other players and their intentions
a so-called Knowledge and Belief base is used. For details refer to
\cite{Kraus88}

\paragraph{DipGame testbed by Fabregues}

Fabregues approach inspired us as they also tried to unify negotiation
and a robust strategy / tactics component \cite{Fabregues11}. Different
from other bots they do not use DAIDE but the newer DipServer. 

\paragraph{SeaNail by Lorber}

The SeaNail AI \cite{Lorber98} uses a Dynamic Programming approach to
maximize the number of campaigns matching the current aims of the
bot. For instance if a supply centre is selected for capture and a
certain defense strength is estimated units that overcome this have to
be selected. For every combination of

\subsection{Strategy-only bots}

\paragraph{Original Hasbro AI}
The AI distributed with the Windows version is commonly 
acknowledged as having poor playing strength. Besides it is not
compatible with the DAIDE framework so we could not use it for
our experiments.

\paragraph{Others}
There have been various earlier efforts to create a Diplomacy bot
limited to DAIDE press level 0 \cite{DAIDEsyntax10}. While early
approaches used classical AI techniques like Best-First-Search there
has been a move towards multi-agent designs that assign agents to
board units or split the problem domain along different tasks. As
negotiating is the primary goal of the project we are re-using
concepts like temporal difference learning \cite{Levinson94} and the
valuation of provinces \cite{Huff05} to create a strong AI player.

%--------------------------------------------------------------------------------

\pagebreak

\section{Motivation}

Many of the aforementioned bots are quite effective decision-makers in
general but few of them support negotiation or reasoning about the relationship of
the powers in the game. Our project aims to create a framework for
Diplomacy, including a GUI client, a game server and a collection of
bots. The highest evolution of our series of bots should be able to
analyze and act upon messages of human / AI players and issue messages
to other players. In particular we aim to unify negotiation and
general strategy, given that negotiation is simply cooperative 
decision-making and only a layer of communication and trust models have
to be added. \\

Finally experiments shall be conducted to determine whether there is a
reward associated with negotation capabilities. This requires careful
study and implementation of automated negotiation techniques from
other domains in AI / Game Theory. Thus the project giving us ample
opportunity to be creative and test different approaches using the
DAIDE-conforming game framework also produced for the project.

\section{Project aims}

High-level requirements were discussed in the initial phase of the
project (weeks 1/2) with our project supervisor. The terms of the
collaboration were such that only certain high-level goals were
defined and decisions about which AI techniques to use were decided once
related research has been explored.

\begin{itemize}

\item The over-arching goal and hence the most critical requirement is
  to design and implement a negotiation bot for Diplomacy. Its
  performance is then compared to existing bots in an experimental
  setting. Through this we would like to answer the question: Is there
  a payoff associated with the use of negotiation or does a stronger
  tactics component always dominate? 

\item A collection of other bots which are not capable of negotiation
  shall be created for purposes of comparison. These should use
  proven techniques from the fields of Game Theory and Multi-Agent
  systems, including learning, tactics and long-term strategies. All
  bots should support the DAIDE protocol to compete against existing
  bots on the DAIDE windows server.

\item To facilitate experimentation an open-source framework
  conforming to the existing DAIDE protocol should be created. This
  framework comprises a server which hosts games for automated and
  human clients and a tool to gather game statistics. The imperative
  behind this is to feed-back into the Diplomacy community as a whole,
  providing a multi-platform server (Windows DAIDE server exists) in 
  Haskell for the first time.

\item In addition a framework for simple generation of Diplomacy bots
  is envisioned: Right now a player needs to re-invent the wheel by
  implementing well-established game-tree search techniques or certain
  Machine Learning paradigms in low-level terms. This is clearly
  unsatisfactory. Our framework helps to shift the focus to
  interesting new techniques from academia which can be coded up and
  layered on top of primitives. Actually this framework is used for
  the 2nd objective above to quickly generate a series of bots with
  increasing functionality.  (Abstract client pattern) This also works
  as a proof-of-concept for the server framework. At the users
  convenience extensions are written in the high-level language
  Haskell which is more expressive than C++ and natural to
  practitioners in the field of Artificial Intelligence / Game Theory.

\item Finally to test our server and provide a visually pleasing user
  interface we deliver a DAIDE-conforming GUI client for the Game
  of Diplomacy.  Rather than forcing the player to use a particular
  device all back-ends of the HaXe platform are supported, including
  HTML5/JS and C++.

\end{itemize}

In the above listing the requirements are decreasing in
importance. Some of the above look indivisible in nature but we have
still managed to extract user-stories to support time-boxed
iterations. Requirements management was two-fold: Each
team-member kept in mind the overall contract with our supervisor (see
above) which defines the direction of the project.  Based on this
User-Stories were defined which guide the primary development focus
during the iterations.

%--------------------------------------------------------------------------------

\pagebreak

\chapter{Strategy and tactics (Rational system)}

A \textit{Strategy and tactics component} is seen as an important
foundation for every negotiation agent. On top of that we are 
convinced that \textit{Negotiation} and \textit{Strategy} are not
really issues that can be cleanly separated; even though previous
literature suggests this. The fact that negotiation is really
joint problem solving in disguise illustrates this nicely.

\section{Challenges in Diplomacy}

Before even thinking about implementing a strategy we came up with
a number of challenges that our bot has to overcome:

\paragraph{Short-term vs. long term payoff}
Pay-offs in Diplomacy are affected by the paradox that short-term
advantages can turn against the bot because of coalition-building:
Consider a bot that rapidly conquers supply centres out of a 
relatively strong starting position. Now it is rational for the
other players to ally against him to prevent him breaking away.
To avoid getting into this ``one-against-all'' situation a player
should aim to be the 2nd strongest power or lead by a small margin.

\paragraph{Tremendous search space}
It has been estimated that the number of possible moves from
an average Diplomacy position is roughly $4.09 * 10^{27}$ 
\cite{Kemmerling00}, rendering a game-tree search unrealistic. The root
of the problem is that our power has \textit{incomplete information} 
about the other power's intentions. Other bounds on the branching factor
of one turn are roughly $6^{n}$ where n is the number of units controlled by a
player. Considering the combinations of moves of all players we get
$2^{91}$ possibilities \cite{Shapiro02}. Thus we did not follow this
path but focussed on \textit{learning} and heuristic move-evaluation
that is aware of mid-term goals.

\paragraph{Deceit}
One of the most fascinating aspects of Diplomacy but also its great
complexity are lies and back-stabbings: As agreements are non-binding
we have to guard against broken promises in our \textit{Strategy finder}
sub-component. 

\paragraph{Move prediction}
As a result our bot needs to predict a move 

\section{The Strategy Finder subsystem}

As listed in the \textit{Introduction} section there were previous
attempts of creating a strong AI for Diplomacy: Kraus \cite{Kraus95}
put emphasis on negotiation whereas \cite{Shapiro02} used
\textit{Temporal difference learning} to guide move selections. For
our AI we augment Shapiro's technique with state utility functions
that should lead to more realistic pattern-weights.

Subsequently we describe the concepts of \textit{move patterns},
\textit{pattern weights} and present our state evaluation functions.

\subsection{Move patterns}

A primitive pattern is a property of a move; Examples are its type,
features of its origin \& destination provinces or estimated support
strength. Each \textit{move pattern} is a n-pattern where n is the
number of primitive patterns that a given move matches. Hence as n
increases a pattern goes from the general to the specific and will
match fewer and fewer moves. \\

Common 1-patterns used by our bot are:

\subsection{Temporal difference learning}

The idea of \textit{Temporal difference learning} is to refine a
database of expert knowledge; in the case of pattern weights we learn
the features of a successful move. All knowledge is maintained across
games. There is no need to prime the bot with any knowledge about
Diplomacy strategies; these are learned through self-play (against
random variations of itself) and games against other players. While 
Shapiro \cite{Shapiro02} updates the pattern-weights after each game \\

\subsection{Pattern learning rule}

After each turn the values of all patterns are updated
according to the following formula. This is derived from
the formula proposed by \cite{Shapiro02}. \\

$Weight_{n} := \frac{Weight_{n-1}*(n-1)+k*v}{n+k-1}$ \\

This is a running average of the pattern-weight determined
in previous game turns and its effect on the game state. \\

Pattern weights start with an initial value of 0.5 (indicates
that pattern / move is neither good or bad) and ranges from 0 to 1. 
Pattern weights also use an age field that indicates the frequency
of update. The age is not used for learning, but provides a bias
for evaluating pattern-weights during game play. $v$ is 1 when
winning conditions are met (i.e. majority of supply centres)
and 0 otherwise. With a larger k, the system values the latest
experience more than previous ones.

The parameter $k$ gives the learning rate; it can be used
to fine-tune the bias on current learning vs. previously
learned pattern-weights. Ideally it would be changed during
the game to implement \textit{Simulated Annealing} with
random restarts. \\

\subsection{Use of TD in LearnBot}
In LearnBot we use Shapiro's research on Pattern Weights
\cite{Shapiro02} to implement an AI which learns how to play the game
by updating a pattern weight database after each game.  We implement
the Temporal Difference Learning which is described above and use the
formula to calculate the weight of the next turn using the previous
turn's weight.  Weights are increased when we have won (v = 1) and
decrease when we have lost (v = 0). We update our database when the
game has ended and update the weighting on all the patterns
(i.e. orders) with the weighting that we calculated for that turn.
When we choose patterns/moves during a turn, we use randomisation
which the weight and age of the pattern/move as a bias, this ensures
that we can continue learning and reinforcing (positively and
negatively) by allowing other moves to be chosen.

\subsection{Extensions of TD}
As is obvious from the formula, changes in weightings may not
necessarily reflect how effective certain moves were and therefore may
not be as accurate in learning. LearnBot improves this by first
calculating a state value for each turn, (i.e. it looks at the game
state after a turn and calculates a metric value). The most simple one
is $\frac{number of supply centres owned}{number of supply centres
  needed to win}$. These values are paired with each turn and then
after each turn we project the difference into the unit interval [0,1]
to update v. This reflects the difference between the 2 state
values. We can then apply this our own function which calculates the
new weight for a move which we then store in the database:

$Weight_{new} := \frac{Weight_{old}*c+k*v}{c+k}$ \\

Here we calculate the new weighting for each move (though the c, k and
v will stay the same for each turn like the evolution formula above).
k is the same learning rate / global temperature that is described in
Shapiro's evolution formula.  c is the a constant that determines how
strong the weights are affected by, so a larger c means a smaller
change. We can tweak this as we go along to find an optimal value.  v
is described above and is a value ranging from 0 to 1 which is mapped
by the difference between state values (which can be between -1 to 1)
with state values themselves ranging between 0 to 1.

\subsection{Joint group planning}
\textit{Joint group planning} potentially happens in every
cooperative multi-Agent system. In Diplomacy we usually develop
strategies, select attack targets with our allies.  

\subsection{Goal queue}
The goal queue holds the current offensive / defensive
goals ordered by priority. Notice that these are abstract
targets and not yet bound to any units.

\subsection{Goal expansion and unit assignment}
This is related to planning algorithms like STRIPS but is
greatly simplified to suit our student project: Basically
the first item of the goal queue is removed and bound to
a set of candidate units that fulfill the goal in some 
number of turns. We chose the simple heuristic of minimizing
the number of unit-timesteps bound by the goal, but it 
is suggested that in an extension of the project proper
Operations-Research techniques like the Aircrew-Scheduling
algorithm are investigated.

%--------------------------------------------------------------------------------

\pagebreak

\chapter{Software architecture}

\begin{figure}

\includegraphics[scale=0.75]{./report4_onion.png} \\[1cm]

\end{figure}

\section{Multi-agent approach}

As Kraus et al \cite{Kraus95} we employ a Multi-Agent approach with a 
central controller internally. The idea is that in each game situation
a different strategy will give the best payoff. When move selection starts
all sub-brains run concurrently and submit a \textit{move set proposition} to
the controller. 

\section{Machine learning}

There are many instances where model parameters are not known a-priori and
are best learned. An alternative solution is to provide expert knowledge 
explicitly, but this has two problems:

\begin{itemize}

\item A diplomacy expert is not available for most AI bot efforts, in 
      particular not for a student project

\item Using compiled strategic knowledge from the Diplomacy archive
      \cite{DipArchive04} was out of the question. Normally there
      is no one-to-one mapping from a particular game heuristic and
      the model parameters. 

\end{itemize}

\section{A brief overview of our subbrains}

\begin{itemize}

\item RandomBot: Selects a random move, for comparison

\item HoldBot: Holds on every turn, the dumbest bot for comparison

\item DumbBot: A re-implementation of the original DAIDE AI

\item LearnBot: Using strategy/tactics for the first time

\item CoverBot: The cover bot has a global view of the board and tries to 
                conquer ``important'' zones.

\item NegoBot: The negotiation bot (including low DAIDE press-levels)

\end{itemize}

\section{Shared components}

A number of components all shared among all sub-brains. We think this is a 
good idea because functions like game state or move metric are so fundamental 
that many (future) are bound to use them. We reap the additional benefit of
better comparability during experiments if some bots share components.

\subsection{Heuristic game-state evaluation}

To get an idea of the Haskell implementation we include the code
for evaluating the state metrics. In this example we measure the
utility of the game state as the number of supply centers owned
and the nature of adjacent provinces around our supply centers. Obviously
supply centres that are close to capturable provinces are worth more:

\begin{verbatim}

State specific metrics

-- given a power returns the number of supply centers owned and non-supply centers occupied
getProvOcc :: (OrderClass o, MonadBrain o m, MonadGameKnowledge h m) => Power -> m (Integer, Integer)
getProvOcc power = do
   suppC <- getSupplies power
   units <- getUnits power
   let occupied_prov = map (provNodeToProv . unitPositionLoc) units
   return (lengthI suppC, lengthI (occupied_prov \\ suppC))

-- returns a three-tuple of supply center control, (you, enemy, no-one)

getSuppControl :: (OrderClass o, MonadBrain o m, MonadGameKnowledge h m) => m (Integer, Integer, Integer)
getSuppControl = do
  mapDef <- asksGameInfo gameInfoMapDef
  let provinces = mapDefProvinces mapDef
  let numSupplies = lengthI . filter provinceIsSupply $ provinces
  powerSupplies <- mapM getSupplies (mapDefPowers mapDef)
  let allSupplies = sum $ map lengthI powerSupplies
  mySupplies <- return . lengthI =<< getMySupplies
  return (mySupplies, allSupplies - mySupplies, numSupplies - mySupplies - allSupplies)

-- returns a three-tuple of province occupation around adjacent provinces only
getAdjProvOcc :: (OrderClass o, MonadBrain o m, MonadGameKnowledge h m) => UnitPosition -> m (Integer, Integer, Integer)
getAdjProvOcc unit = do
  provNodes <- getAdjacentNodes unit
  let provs = map provNodeToProv provNodes
  unitPoss <- (getAdjacentUnits.provNodeToProv.unitPositionLoc) unit
  myPower <- getMyPower
  let ourOcc = lengthI . filter ((myPower ==) . unitPositionP) $ unitPoss
  let enemyOcc = lengthI unitPoss - ourOcc
  let noOcc = lengthI provs - lengthI unitPoss
  return (noOcc, ourOcc, enemyOcc)

\end{verbatim}

\subsection{Province valuation}
During goal selection a bot needs to calculate its future strategy
preferences. Hereby we take into account the strategic position of 
provinces. We can have two type of goals:

\paragraph{Province or zone defense}
A supply centre defense goal is selected according to its value
determined by \textit{province valuation} and its risk-factor. The
risk factor is proportional to the number of adversary units that 
can reach the supply centre in the upcoming moves. This also determines
the required strength of the defense.

\paragraph{Supply centre conquer or zone advance}
This offensive goal selects a province that has relatively weak 
defense compared to its value. Again the \textit{province valuation}
component is used.

%--------------------------------------------------------------------------------

\chapter{Negotiation Bot}

As for the overall bot architecture we have chosen a multi-agent 
approach. There are clearly sub-tasks which a negotiator needs to
provide. Each of them is mapped to another thread.

\paragraph{External communication (Message dispatcher)}
The \textit{External communication} has interfaces to the agreement 
and relationship database and can be seen as our connection to the
environment of allies of foes. One of its functions is to propose
joint strategies deemed good by the \textit{Strategy finder} to its
allies (which it looks up from the \textit{Relation database}. Seen
functionally the communication component creates concrete DAIDE
messages from abstract sub-goals. Current sub-goals are provided
by the tactical component including LearnBot and CoverBot. Speaking
with the government analogy of Kraus \cite{Kraus89} these are the
\textit{Ambassadors}. Different from the Israel Diplomat we do not
have one \textit{Ambassador} per power but created one such 
component. This simplified testing considerably. 

\paragraph{Suggestion dispatch}
It is a well-known problem in \textit{Automated negotiation} how 
to react to move or strategy suggestions. At the highest level there
are three possibilities:

\begin{itemize}

\item The move can be internalized and treated as if our own 
      Strategy component came up with it. 

\item The move or strategy can be adopted with the reservation 
      that future evidence might invalidate this decision. This 
      requires an \textit{Agreement table} to keep track of such
      item.

\item The move can be cross-checked by our own brain and only 
      adopted if it is in line with our current goal-queue. 

\end{itemize}

The \textit{Suggestion dispatch} has access to the Knowledge and
Belief base of our bot. For obvious reasons suggestions by
adversaries or bots that are believed to have poor judgement 
should be cross-checked while those of allies receive fewer
scrutiny . \\

\section{Emotional subsystem}

The emotional subsystem serves three purposes:

\begin{itemize}

\item Although not strictly necessary it is handy to model
      human-like attribute with the bot. We propose a
      \textit{static character traits record} that is 
      initialized upon personalization of the bot. In an 
      extension we hope to provide dynamic behaviour by
      varying this from game to game.

\item The bot needs to infer \textit{Relationships} of the
      other powers. This is primarily driven by stochastic rules.
      For example if Turkey attacks Germany we can be reasonably 
      sure (it might be bluff with small probability) that these
      powers are adversaries. The corresponding triple in the
      relationship table is ([at war],[Turkey],[Germany]). In the  
      same manner other relations between powers can be inferred. 
      Note that the rules are hard-coded and there is currently
      no way of of \textit{learning} them in any way.

\item Lastly we want to infer a character profile from a powers actions.
      These include objective measures like Risk-averseness or 
      hoarding-tendency but also subjective ones like our own 
      liking or trust of the respective power(s). As the relationship table this
      is updated via pattern-matching on the other power's moves and
      evaluation of several game-statistics (like the change in 
      state metrics from the perspective of other powers, where positive
      changes indicate high playing strength). The limits to what can
      be measured abound and we left it deliberately open-ended. A good
      inspiration are the feeling models by Weiner and Graham or 
      Parrot, although initially we only include coarse-grained primitives
      like  'Fear', 'Happiness', 'Sadness' and 'Anger'. Notice lastly that
      we commit to sentiments we have inferred and remove them only 
      when evidence to the contrary has been established. Hence we cannot
      partially revise beliefs or determine partial happiness etc..

\end{itemize}

\section{Agreements database}

The agreements database holds commitments of our bot with 
other powers. It is populated by the \textit{Message dispatcher}
component explained above. \\

An example triple is ([Turkey],[Germany],[AttackProvA]),
notice that the last part is a goal that can be processed by the
\textit{Goal expansion} unit of the \textit{Strategy subsystem}.


%--------------------------------------------------------------------------------

\chapter{GUI}

\input{./report4_gui.tex}

\pagebreak

\chapter{Software engineering}

\section{Change management / Risk mitigation}
We recognized that change is inevitable in such an ambitious and
multi-faceted project. Therefore we took great care in defining our
contracts carefully to split up work. Actually this was helped
substantially by the existence of the DAIDE protocol. Through its
rigorous specification it forced everybody to program to an existing
interface and there was little scope for confusion as to what needs to
be supported.  \\ Each of the high-level objectives outlined above can
be achieved separately and as a result there are little dependencies
between team members.  If communication between two components fails
it is matter of determining which are not properly realizing the DAIDE
protocol. A welcome side-effect is that we avoid endless debugging
sessions to make two parts of the project work together. They just
need to be tested against a DAIDE reference.  \\ Using the 'AI
generation' framework explained above implicitly makes coding of AI
techniques incremental. For instance if a well-tested game-tree search
or Learning algorithm is in place, each evolutionary bot can delegate
these tasks without worrying about how they are implemented. Turning
this into a reality required defining a layered design in Weeks 3-5
which all future work respected.  \\

\section{Planning / task estimation}
All planning took place in the weekly group meetings (for the
structure of a meeting see example at the bottom of document ). A
general rule for new user-stories was that they relate to the global
objectives defined in the contract with our supervisor (see
above). This avoided falling ill with 'featuritis' at any point in the
project.  \\ In the AI realm a new user story was typically introduced
by a team member. Generally we shied away from implementing exotic
algorithms that are not clearly understood by all team members,
adopting the ``Kiss principle''. Also there should be a balance
between different paradigms in the AI design, which enables us to make
meaningful experiments for the final report. For instance it is not
seen as fruitful to performance-tune beyond the point where much value
is generated on the whole. Rather the focus should be on
negotation. Associated with each user story we started a quick poker
game to estimate the required time-resources for completing the
feature. Obviously members with more experience in a domain were given
more weight in the decision process.  We usually arrived at a decision
about a future iteration unanimously.  \\ For the server the process
was less creative and controlled by the need to conform to the DAIDE
protocol. Conversely planning was easier because the process of
creating a parser is understood by all team members.

\section{Progress metrics}
There are multiple ways in which we can measure the progress of our
AI.  We adopted an aspect-oriented approach in measuring, recognizing
that some requirements are fulfilled qualitatively and others can be
stated in terms of numbers.

\begin{itemize}
\item A natural but informal progress metric is to simply estimate for
  each high-level objective defined in the contract a percentage of
  the features which have been successfully implemented. This places
  emphasis on the big picture rather than measuring the performance of
  a particular bot we have created.
\item Another metric which only pertains to the AI side-of-things is a
  quantative measure of how do we fare against typical existing
  bots. Such a metric could be gathered for example in a Round-Robin
  tournament.  As a canonical example we adopted the existing DumbBot
  which despite its name has considerable playing stregth. According
  to our supervisor systematically out-performing DumbBot presents the
  technical benchmark for the project.
\item Relevant to the server-framework and the GUI client we can
  define a measure by the percentage of valid DAIDE messages
  supported. Once this is close to 100 \% it immediately follows that
  both are DAIDE-conforming, one of our objectives outlined above.
\item As a GUI is hard to test automatically we left 10 mins of our
  weekly discussions for informal game walkthroughs. All team members
  judged how natural / visually pleasing the interface was and what
  features could be supported in the next generation. We have not used
  any formal methods here but trusted our experience with playing
  similar strategy games.
\end{itemize}

\subsection{Detailed AI metrics}

Within each of these milestones, we can weigh a bot's ability using
its only application - playing the game of diplomacy. For this, we
need to come up with a set of metrics with which we can evaluate a
players performance in a game. We are planning to equip the server
with a tool to measure these statistics during the game. By combining
these indicators in a weighted fashion (possibly with some needed
calibration), we should be able to compute an accurate score of how
well a particular AI is playing. This can be validated by measuring
the correlation with a high-score and the number of games won/lost.
\\ Some key indicators are, with some having precedence over others:

\subsubsection{Games won/lost} 
This is clearly the most important metric and overrides all others.
However it gives little insight into what actually caused a bot to
lose or win the game.

\subsubsection{Supply centres controlled}
With regards to supply depots, the winning player will own half of
them (eighteen), with the second-most successful player owning the
second highest amount, and so on and so forth. A player with no
supply-depots is very close to becoming a losing player.

\subsubsection{Units lost during the game}
Units lost is a difficult metric to quantise - whilst it may
immediately seem that losing many units is a bad thing, these could be
due to tactical masteries involving trappingand deluding many
foes. Objectively, it is probably advisable to refrain from losing
units where possible.

\subsubsection{Provinces conceded during the game}
Similarly, conceding provinces, unless done in a planned fashion, is a
general indicator that a player is not performing well.

\subsubsection{Negotiation 'strength'}
If it were possible to evaluate other players' "attitudes" towards the
AI player, one might be able to deduce the competence of a bots
negotiating skills. For instance, making enemies is widely regarded as
a poor move, especially if those enemies are actively hostile against
you. A better tactic might be to give them the illusion of friendship,
whilst aligning them for a back-stabbing manouever. If we could create
a way to reliably score the subtleties of negotiation between players,
it might aid us in the creation of more advanced diplomising AIs.

\subsection{Team velocity / Milestones}
We can define our team velocity as the positive change in progress
metrics overall.  This means that we can allocate team members to the
metric which currently has priority. These are typically the ones that
are covered by the user-stories for the current iteration. Having said
that we strived to progress in each part of the project to discover
problems and dependencies we have not anticipated early.  \\ Whereas
the velocity-scheme served as a tool to measure our progress
internally we communicated our progress to the supervisor in terms of
coarse-grained milestones. This had the advantage that we did not
overload our customer with technical details that only we as
developers care about. Also they co-incided with the frequency of
meetings with our supervisor.  \\ The milestones agreed upon were to
create the AI framework and the server, and then proceed to iterate a
build of an AI, progressively increasing its abilities and making it
better.

%--------------------------------------------------------------------------------

\pagebreak

\section{Validation}

\subsection{Server testing}

\begin{itemize}
\item A very practical and simple method for us to test the server is
  to let RandomBots join a game and issue arbitrary move commands. We
  estimate that we get good coverage using this method since a random
  bot is expected to issue every possible move over a large number of
  games. We expect that the server does not crash and advances the
  game state correctly. We check successful completion by checking for
  any error return codes / exceptions thrown by the server. The latter
  is tested by cross-checking the game state with the Windows DAIDE
  server which we forward all messages that our server receives. Since
  both observe the same game the messages send to clients should not
  differ. To automate the tests, we created a script that intercepts
  client-server communication and then invokes 'diff' on the messages.

\item To inspire further confidence in the code's correctness we use
  the Quick Check tool developed for the Haskell platform: Given pure
  Haskell code (that is containing no I/O) it generates random
  function inputs and theoretically allows us to test a function
  exhaustively. For instance to test a parsing function we can specify
  the invariant that it accepts precisely the members of the DAIDE
  language and returns a parsing error otherwise. For the 'state
  advancing logic' of the server we can check certain properties that
  we know to be true in general. An example would be: A supply centre
  can only be conquered if an army of the player was sent there. We
  decided against a parallel module hierarchy for the tests but
  instead defined submodules of the form 'X\_quickcheck'.  This
  allowed us to use the tests as documentation when writing the
  functions and avoided synchronization issues. This also facilitates
  testing of functions that are not exported from a module.

\item To augment testing with QuickCheck one team member has encoded a
  number of representative game situations as unit test cases. Largely
  these were taken from the DiplomacyRuleBook, one of the references
  that specifies correct state advancement. The unit tests were
  written in HUnit, whose feature-set largely parallels JUnit for Java
  programming. The whole testing framework can be automated, tests
  being packages hierarchically in test suite, modules and
  collections.  As QuickCheck tests they live in a module sub-
  ordinate to the functions tested.
\end{itemize}

\subsection{AI client testing} 

\begin{itemize}

\item A very simple test is to determine whether an AI client does not
  impede the progress of the game. This can simply be tested by
  letting the client on either the functional Haskell or the existing
  DAIDE server (Windows). The script running the test will intercept
  any error messages issued to the client and deem the test to be
  failed if any syntax errors (no valid DAIDE message) or semantic
  errors (moves that do not make sense with respect to the current
  game-state) were flagged.

\item Anything that goes beyond liveness and absence of errors cannot
  be tested trivially. Instead of testing we let bots play in
  Round-Robin tournaments, collect game statistics and assign each bot
  a playing strength metric. The exact way and the ingredients of the
  formula were outlined in the section on 'AI metrics'. Ultimately
  playing strength equates to faring robustly against a large
  collection of existing bots.

\item Some white-box testing was done to determine how the AI arrives
  at a decision and check if its reasoning is sound. We designed the
  different parts of our AI with testability in mind, often using very
  tiny functions. As an example consider an interface that measures
  the utility of a game state to a certain player. It can be tested by
  simply comparing the result with our pen-and-paper calculations.
  Some of these tests were coded up as HUnit test suites.

\end{itemize}

\subsection{GUI client testing}

\begin{itemize}

\item For the GUI client similar criteria to the AI client
  applied. The client should be live during the game and not issue
  mal-formed messages. A simple script that instruments the GUIs
  command-line interface was put in place for this.

\item Unit testing in the HaXe proceeded as recommended in its manual:
  Simple test cases to check correct parsing of SVG files (encode the
  map topology) were created by subclassing a TestCase and putting
  appropriate checks in place.

\item Functional requirements were largely in-tangible, such as
  presenting a intuitive, visually appealing interface to the
  user. Our division of labour allowed that team members involved in
  the AI could give feedback.  Roughly 15 mins of each meeting were
  dedicated to discuss the user interface: flagging new issues and
  tracking progress on fixing previously discovered bugs. These tests
  were conducted for each end-user device targeted by the HaXe
  framework, such as mobile phones or internet browsers.

\item While there exist tools for automated-checking of web interfaces
  the team dismissed this as misguided effort better spent elsewhere.
  The marginal utility would be to know that all buttons worked
  correctly which can also be tested by manual inspection.

\end{itemize}

\subsection{Static code checking / tools}
All deliverables, including code and documentation was produced using
Emacs / Gedit or other similar simple text editors. We have not used
an IDE but several Emacs modes and extensions (directory browsing)
helped us to keep track of the overall structure of the codebase. Our
strategy to achieve good coding style was readability was two-fold:
Rather than making up our own coding standard we have adopted the
programming guidelines from
``http://www.haskell.org/haskellwiki/Programming.guidelines''. Secondly
each team member was required to run each (compiling) commit through
'HLint' and the 'Haskell Style Scanner' and resolve issues if
necessary.

\subsection{Code documentation}

We treated documentation as a deliverable only second in priority to
working code. The coding standards defined at the beginning of the
project detailed the style of documentation and good practices to
avoid running-out-of-sync issues.

\subsubsection{Developer documention}

Developer documentation consisted of JavaDoc-style comments for each
data type, typeclass (interface) and function documentation. The
particular tool used is ``Haddock'' which allows generation of API
reference pages (HTML).

\subsubsection{User documention}
Besides documenting exported API through ``Haddock'' (primarily the AI
framework for creating Diplomacy Bots) we agreed that tutorials need
to be written to explain typical use-cases of the library. Only then
can we hope that our library is re-used by other members of the
Diplomacy community which was an objective defined at the outset of
the project. Team members agreed that once we go public with our
project (BSD open-source licensed) we also need to have a Sourceforge
website.

\subsection{Code inspection / Refactoring}
Each function of the code is ideally represented in three different
ways: as executable code, unit test and exported ``Haddock''
comments. For some trivial cases one of the latter might be
missing. This approach has simplified code inspection and walkthroughs
tremendously. In a typical 'design-check' session which is conducted
roughly fort-nightly a team-member will check a particular code in
detail. This involves clarifying comments, naming of functions and
checking overall soundness of design. Often major refactorings were
suggested as it was discovered that pieces of code were conceptually
similar and hence could be extracted into a common module. Not only
were we challenging our tendency to 'repeat ourselves' in the code but
also could spread knowledge about the code-base in the entire team. By
the regularity of refactoring / design effort we wanted to avoid that
the code-base grows out-of-shape and acquires ``technical debt''.

\subsection{Acceptance tests}
Acceptance testing has not yet been finalized. In a recent meeting
with our supervisor we conducted a short walkthrough of the GUI to
gather feedback. The functionally we have implemented was received
well, with some minor changes suggested. Final integration / system
testing will be done during the holidays and the first week of the
Spring term. We aim to keep our supervisor involved by sending regular
screenshots of the GUI and results from the Bot-tournaments.

\subsection{Stress testing}

\subsubsection{Server loading}

Our server can be stressed by increasing its load, flooding it with
malformed messages in spirit of Denial-of-Service attacks. The overall
aim is to find a threshold load under which our server just
crashes. Another test is to connect multiple AI clients that issue
conforming DAIDE messages at a rapid pace. The question then is
whether the server still advances the game state correctly. If this is
not the case we would need to check the server code for possible race
conditions explicitly. Initial measurements indicate sufficient
robustness.

\subsubsection{AI / GUI client loading}

In a similar fashion GUI and AI client can be run against servers
issuing malicious messages at a rapid pace. We allow arbitrary
behaviour in this case, but the client should still discover the
problem and disconnect safely. Similarly we have to defend against an
adversary who addresses spam to force our player to time-out during
move generation.

%--------------------------------------------------------------------------------

\section{Project evaluation / experiments}

%--------------------------------------------------------------------------------

\section{Managerial Documentation}

\subsection{Collaboration tools}
We discovered that the best tool was actually gathering in front of a
white-board (we did not yet have IdeaPaint TM), sticking some user
story cards and talking through the overall design. Simplified UML
diagrams and examples were used to elaborate design alternatives at
our disposal. Anything that was of permanent value to the team was
usually recorded in a logbook (see example of a LogBook page
below). For this purpose we assigned a member to take minutes of each
meeting and create a digest that would be put into the issue-tracking
system of GitHub. Other resources of GitHub, such as progress, issue
flagging and milestone setting were used sporadically. Next time we
would probably use a more sophisticated tool for resource management,
enabling us to categorize research papers, coding standards, progress
reports in a better way.

\subsection{Version control}
The distributed source code control system Git was used for all
deliverables - that is unit tests / documentation, tutorials and
presentations. We have made it strict policy to avoid both conflicting
/ non-compiling commits. The former required good coordination between
team members about which files should be edited in what
time-window. Any file that is machine-generated should be ignored by
the file tracker to avoid confusion and wasted memory space in the
repository. For simplicity we avoided working on different development
branches. All code was backup-ed in the project directory of DoC at
regular intervals.

\subsection{Automated build}
The CABAL package management system was used as recommendend by most
Haskell coding standards. The different parts of the project (Server,
Client, AI) were packaged separately to avoid annoying compile
dependencies and allow team members to work separately on different
components. In our judgement a suitable CI server does not exist for
Haskell and using one would have been overkill.


%--------------------------------------------------------------------------------

\pagebreak

\chapter{Summary and outlook}

\section{Self reflection}

\subsection{Goals vs. available time}
In hindsight the goals we had set at the beginning (see first section
on ``Project goals'') may have been too ambitious: Building a
Diplomacy platform from the ground up including the server, the user
client and the AI and negotiation took a lot of coordination effort
and work at all fronts. Regardless during a period of roughly 2 months
we have achieved a lot both in terms of experimental results and size
of the created software (GUI, Server and bot framework). In summary we 
learned that it pays off to channel the energy of the team members 
rather than working on totally separate products.

\subsection{Group coordination} 
We learned that working a group requires an experienced project
manager and one person steering the overall design / interfaces
between components. This was especially important in our project 
because we set out to build a framework and not just a collection
of bots.

\section{Time estimation}
We had to re-plan halfway through the project -- unfortunately
building the server took more time than expected and
we had to avoid running out of time for the main aim: 
negotiation. Using the DAIDE server for bot testing provided
us with a plan B in case delays on the server would accumulate.

\section{Knowledge transfer}
One of the main difficulties was getting the group up to a reasonable
level in monadic Haskell. Most members of the group did not have much
experience with monadic programming in Haskell while another excelled.
Nonetheless our group sticked with Haskell as this provides a 
powerful combinatory parsing library \cite{ParsecLib} for the server.
Given that the project focus shifted towards the AI at the end we 
would consider using Java in a similar future project. \\

Similarly, GUI design, AI design, general coding skills and practices
all varied. We have remedied this somewhat by working in pairs or
more, allowing the parts of the knowledge to diffuse (in a manner
similar to osmosis :) ) between group members as problems are
encountered and solved. Additionally, papers and other learning tools
have been shared (via GitHub and Gmail) to aid the code writing
process. Where learning-by-application and reading have failed, group
members have also been keen to help each other, spending time drawing
UML diagrams and explaining concepts in detail. The focal points of
these discussions have usually been the weekly group meetings. Logbook
allowed us to document what we have learned and avoid introducing bad
design / bugs more than once.  \\ Last but not least we decided to
have a ``glossary'' section in the log-book where we explain give
names to the most important concepts of our design. For instance we
have defined the AI framework in terms of metaphors from the
Neuroscience domain (Brain etc..). For this to be effective and
improve communication every team member needed to be aware of the
terms.


\subsection{Choice of implementation language}
In retrospect Haskell was not an optimal choice when i t comes to
collaboration between team members as the skill-set of team members
was different. In addition many aspects of design are naturally
expressed using UML which is easier to translate into the
``Object-oriented paradigm'' supported by Java or Python.
Having said that Haskell had its merits when it comes to implement
DAIDE message parsing on the server (Parsec library \cite{ParsecLib}) 
which is why it was chosen in the first place.

\pagebreak

\section{Conclusion}

In this project we created a negotiation-capable AI framework for the
game of 'Diplomacy'. On the tactics-side a pattern-weight learning
algorithm \cite{Shapiro02} coupled with a best-first search strategy
and a number of heuristics has been used. We have shown that negotiation
and strategy are similar and integration was succssful. The
subsystem comprising GUI client and server has been implemented partially.
While we are quite pleased with the GUI the server needs additional 
stress-testing to augment DAIDE one day. The experimental results 
are not yet finished because of issues with server testing. They will 
be included in a supplementary section with the presentation.
On the whole we feel that we have made progress on many fronts and
profit from this experience in our future careers. 

\section{Future work}

Due to time constraints in testing we have not been able to explore as
many routes as we would have liked. To name just a few of them: 
\\
\begin{enumerate}

\item Improvements to pattern weights (and LearnBot) as described in
  Ari Shapiro's paper on pattern weights. For example future patterns
  should take into account specific locations of other pieces.

\item Perform temporal difference learning of games played by humans
  and store that knowledge in a pattern-weight database. We could not
  do this as we do not have support for human players on our user
  client.

\item Extend the user client to allow a human user to play Diplomacy
  with a tutorial to aid new players and create a well designed UI.
\item To be able to optimise negotiation features, like when the best
  time to backstab is, this is one of the most important aspects of
  the game and makes the difference between winning or losing.

\end{enumerate}

%--------------------------------------------------------------------------------

\bibliographystyle{plain} \bibliography{report4}

\end{document}
