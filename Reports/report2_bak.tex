\documentclass[12pt]{article}
\usepackage{fullpage}
\usepackage{cite}
\usepackage{date}

\title{Automated negotiation in the game of diplomacy - Report 2: Progress & Revisions}
\author{Matthias Hueser, Andras Slemmer, Luca Deltodesco, Luke Tomlin, Cliff Sun}
\date{today}

\begin{document}
\maketitle

\section{Project progress}

\subsection{Reminder of targets for 2nd iteration (weeks 3 - 4)}



Start initial work on the AI. Continue to improve and develop game
foundation (work will need to be split between team members here).
AI should be able to play a 'holding' game and fulfill all requirements
to play with other AIs. Begin research into tactics and how we will
develop the AI.

\subsection{2nd Iteration (week 3 - 4) Progress}

\begin{itemize}
\item Currently have a working Haskell server which can communicate with
the front-end interface written in Haxe. 
\item Parsing on Haskell server side (using Parsec) is complete up to press
level 10 
\item Front-end interface currently consists of a command-line interface
which can accept messages, parse it and send and recieve the message
to/from the server
\item Representation of the map is complete, i.e. provinces, their adjacencies
and whether they're land/coast/sea
\item Ability to have expandable maps (or different maps entirely) is implicity
from the way the map is stored and represented
\end{itemize}

\subsubsection{Problems in the latest iteration:}

\begin{itemize}
\item There was a problem initially implementing the Daide low-level errors.
If a message fails to parse, an error token needs to be inserted at
the place/token it failed to parse. However Parsec takes the message
as a stream and therefore it is not possible to insert into a stream. 
\item The solution is to save the position where the parsing failed and
then insert the error token outside of Parsec where the message is
a list rather than a stream
\end{itemize}


\section{Revisions}


\subsection{Changes/Revision}


\subsubsection{Time Constraints}
\begin{itemize}
\item Writing the Haskell server and parser has taken longer than expected
and with all the time needed to do courseworks and industrial placement
applications, the project has gone behind schedule
\item This means that there is less time to work on the AI and negotiation
features but after discussion, the team has decided that there is
still sufficient time to complete all current objectives
\end{itemize}

\subsubsection{(AI) Bot Design }
\begin{itemize}
\item Following on, the focus from now until the end of the current iteration
will be on designing and implementing a bot with effective AI. An
iterative approach will be taken for implementing the bot to ensure
that features are properly implemented and that there is always a
basis to work on (see below)
\item Non-negotiating bot can be tested against Dumb-Bot for benchmarking
and to make more optimisations and adjustments to it
\item Final negotiating bot can then be tested against other negotiating
bots to see it how it matches up, this will be the main test to see
the negotiating AI is an improvement over existing AI's
\end{itemize}


\subsection{Revised Schedule for next iteration (weeks 5-6)}

Targets for the next iteration were discussed, more specifically on
how to design the AI. The team further discussed how to split up the
work from this point onwards and decided that 2 people would work
on creating the initial AI bot and the other 3 would work on finishing
the server (i.e. order resolution). The following is a more detailed
account of what the deliverable should look like at the end of the
next iteration/sprint:


\subsubsection{Order resolution implementation}

At the end will be able to resolves all orders in one round sent by
the players
\begin{itemize}
\item Checks that orders are tactically valid and calculate the end result
of all orders, i.e. map state after the round

\begin{itemize}
\item Checks if orders clash or conflict and resolve them correctly
\end{itemize}
\end{itemize}

\subsubsection{AI Bot Requirements}

The following points show an iterative and high-level approach that
is to be taken in building up a bot which houses the AI features (further
discussed below in {[}2.3 AI Techniques and Design{]}:
\begin{enumerate}
\item Initially create a Hold-Bot which will hold for every move

\begin{itemize}
\item Hold-Bot will essentially serve as a template to build upon and will
need to be able to respond to messages from the server (such as negotiation
requests) with a default response (as such features have not been
implemented in the bot at this point)
\end{itemize}
\item Features can then be added to Hold-Bot to create Random-Bot

\begin{itemize}
\item Random-Bot will generate a list of moves that it can make (based on
the current state of the game and map) and will randomly choose a
move

\begin{itemize}
\item AI techniques for being able to search through the game state to generate
a list of possible moves are discussed in {[}2.3 AI Techniques and
Design{]}
\end{itemize}
\item Random-Bot will still respond to messages from the server in a default
way (like Hold-Bot does) but when asked to make a move will choose
a random one
\end{itemize}
\item Adding more advanced AI features so that the bot is able to choose
the best/most appropriate move -> Tactical-Bot

\begin{itemize}
\item Tactical-Bot will use defined tactics to choose a move which suits
the goals it's trying to achieve
\item General tactics need to be defined based on Diplomacy rules (to make
it as general as possible with the possbility of using expandable
maps)

\begin{itemize}
\item Such as prioritising keeping all your provinces in your territory/one
area
\item Or trying to capture as much opposing provinces as possible and not
care as much about your own
\item Or capturing other provinces may be more important than keeping your
own and building as many supply centres as possible
\item Being Offensive (aggresive) or Defensive (passive)
\item AI Techniques and theories used to implement such heuristics are discussed
below in {[}2.3 AI Techniques and Design{]}
\end{itemize}
\item \textasciicircum{} {*}NEED TO ADD MORE THINGS ABOUT AI SPECIFICATION{*}
\item Many possibilities here and taking the time to experiment around with
the tactics will show us which ones are more effective against others
\end{itemize}
\item In conjunction, negotation can also implemented into a bot -> Negotiation-Bot

\begin{itemize}
\item Will be able to deal with negotiating with other bot/players
\item The code base for negotiation bot will be seperate but can me made
to work together with Tactical-Bot as one bot
\item This ensures good modularity between the two bots and means that tactics
and negotiations can be built seperately to minimise interference
between the two
\end{itemize}
\end{enumerate}

% Explanation of the Artificial intelligence architecture,
% including pattern-weights, distributed solving and search heuristics

\section{AI Architecture}

\section{Challenges for AI player}

Diplomacy is generally seen as an interesting sandbox to explore
different AI techniques for multiple-player strategy games.

It can be classified as a multi-player, cooperative, zero-sum game
with imperfect information, all of which have important ramifications
for the development of an AI.

Each player has imperfect information because the game state is not
changed in reaction to each players movement separately. Instead a 
so-called 'move-resolution' phase takes place. Here players formulate
their moves in secret and then submit them simultaneously to the game
server which resolves any conflicts, 'standoffs'
in Diplomacy parlance. Being unaware of the others players actions means
that the immediate effects of its own movement orders are uncertain. The
game mechanics dictate that at the end of a turn a chain of so-called 
stand-offs might occur, in case several move order conflict. As a result
an AI player is uncertain of the effect of its own actions. Another matter
that increase uncertainty are support orders that bias the resolution of
stand-offs in favor of a particular player. 

Diplomacy is cooperative since negotiation is at the heart of the game:
It allows players to communicate their short- / long-term intentions before
their actual moves are revealed. For instance in stand-off situations it will
enable two players to attack a field of a third-party. In general negotation
will decrease uncertainty but it can be a double-edged sword. Players might
pretend their actual intentions but actually conspire to betray each other. Hence
in essence an AI player will need to establish whom to trust when considering
his options based on the messages of other players.


\section{Iterative AI development}

An iterative approach is envisioned where generic techniques
like 'Game tree search' are implemented first. The reason for this is that 
search is generally considered as the easiest to implement. Apart from
a utility function mapping a game state to a certain metric vector no 
domain knowledge of the game is required. It is considered a primitive
approach but is required to create a foundation for further development.

As discussed in the next section powerful AI play requires learning of
techniques and responses to typical game situations. The 'partial-state
database' outlined in the next section will form the second iteration
of the AI. 

Throughout the implementation of the two components 'search' and 'knowledge
database' emphasis is laid on generality which enables a close integration
with the 'negotation module', which enables intelligent forming of 
alliances and communication of intentions to other players.

\section{Short-term game tactics}

For short-term game tactics a search with minimal look-ahead can be used.

\subsection{Searching the game tree}

Searching a game tree is considered a generic technique for playing 
games that have discrete states connected by edges which represent movement
orders. As outlined in the introductory section there is uncertainty about
the effects of movement orders, making the viability of this approach doubtable. 

Besides at any given state of the game there is large number of moves possible
for each player, giving rise to a large branching factor in the game tree. [SHA08]
have estimated the number of a possible moves in a game situation to be on the order
of $2_{91}$ to get a feeling for the numbers involved. Even moderate look-ahead in
the search space almost certainly puts a strain on the computational resources.
To overcome this difficulty, search heuristics for pruning the game tree and scheduling
the exploration order of the game branches are alternative-less extension of a
brute-force search. Both techniques can be implemented through so-called utility function
defined on a game state. We discuss the structure of utility functions for Diplomacy
in a later section.

As [SHA08] have argued, modelling the game with payoff matrices is similarly mis-guided
as a brute-force game tree search and so we have not considered it for our AI player.

\subsubsection{Search heuristics}

Whenver a brute-force search is not possible we need to assign a utility to an 
intermediate game state, in which the winner has not yet been determined. On the 
one hand this enables us to cut-off a game-tree search at a shallow level and
still propagate move values upwards through a MinMax procedure. On the other hand
they enable us to guide the MinMax by scheduling the exploration of branches or
pruning branches with limited attractiveness altogether. Even generic heuristics
like AlphaBeta-Pruning or NegaScout that do not use any knowledge of the game give
speed improvements of several orders of magnitude [REFERENCE]. Hence we expect
informed searches to give us considerable latitude to search deeper. 

\subsubsection{State evaluation function}

The aforementioned state utility function will need to incorporate knowledge
of the game to be effective. As the objective of the game is to control the 
majority of the supply-centers any utility function should consider how likely
it is to gain additional centers from a given game state. [Loeb92] propose to 
weight the control centers controlled by a player. Supply centers that are
prone to be attacked in the next turns have a smaller weight whereas ones with
a solid defence base have high weight. All of these functions are blind to 
alliances / cooperations between players in the sense that they treat every 
player as an adversary. A better heuristic would consider the positions of
all allied players collectively, given that there exists some trust bond
between the allied players. 


\section{Long-term strategy templates}

Selecting a long-term strategy will either require hard-coded 
knowledge of the 'Diplomacy' domain or a self-learning approach which
bootstraps an experienced AI starting from primitive playing techniques.
Storing and retrieving learned patterns about the game will be key to build
a catalogue of patterns which can be used to select a suitable strategy.

\subsection{Strategy acquisation}

Several choices: 

a) Hard-coding of offensive / defensive 
   strategies that are played in certain
   situations

b) Start out with rudimentary strategies that
   are extended through learning from previous games.
   (see section 'Learning on previous game-databases')

\subsection{Expert game knowledge}

To improve the AIs playing skills over the lifetime, a
knowledge base with various parts needs to be constructed.

According to the current game state and other parameters, such
as the remaining time in the game or a model of the other players
the agent picks a response rule and generates from it a candidate
move. 

As [SHA08] propose, a game database contains partial-state -> response movement
pairs. A partial state is a high-level description of a state, omitting
details which are not relevant to the formulation of strategy / tactics. If
such a mapping is not found the current state is classified and a candidate move
is created using search techniques. Having found this move, a new entry in the 
database is created. At regular time-points in the future a payoff is calculated
(based on future game metrics) and associated with the new partial-state -> response pair.
The motivation behind this is to rank responses to typical game situations. This
approach reduces the computational load as search is a very costly operation in the
game of Diplomacy. Besides ranking newly-created response upon termination of a game
all used movements are re-ranked using a process called 'Temporal difference learning'.

\subsubsection{Partial game-state encoding}

To enable storing the game data-base its representation must be boiled down to 
the basics required for informed decision making. If necessary additional data
structures like graphs need to be constructed to embody higher-order knowledge
not immediately obvious from a primitive description of the map. 

As [SHA08] suggest, we can construct a hierarchy of pattern-weights where more 
general ones 

a) The current position of all players units
b) A model of all other players (see later) in that situation 
b) Game parameters, including game phase
c) The history of the game


\subsubsection{Opening games}

The opening of games is a special case since a large number
of tournament opening books exist. Since these initial states are amenable to
analysis we can assume that master players had ample opportunities to
pick optimal strategies. Our AI agent has access to such a collection
and will pick a suitable move according to his denomination.

\subsection{Move generation}

Given a description of the game state the AI players classifies
it with respect to several properties and assigns to it a 'partial state'
which is taken from an evolving pattern database. For example in a cooperative
setting a coordinated attack on an opponent would classify as a distinct
'partial state'. As this shows the description should be formulated a level
above move descriptions, so that a chain of movement emerges.

\subsection{Offensive strategies}

\subsection{Defensive strategies}

\subsection{Measures of a player position}


\section{Negotiation component}

The sub-system of the AI responsible for negotation
is seen as virtually independent from the search techniques
and expert database discussed above. Nonetheless it is 
considered vital when competing against players which
use negotation. Consider the situation where offensive alliances
are created against the AI player. To overcome this aggression 
the AI player needs communication to organize defense and launch
retaliation attacks. The product of negotiation are commonly
collective strategies which guide the army movements of the
individual players. In order to safe-guard against other
players who propose reckless strategies those are always
cross-checked against the movements favoured by the search
and knowledge base components.

\subsection{Internal model of other players}

\subsubsection{Trust}

Trust as a relationship between two players removes contingency
from the 'move search process'. This is because certain actions such
as an attack on its own units can be ruled out if a substantial bond of trust
has been established. Besides consistent actions, communication
is needed to forge such relationships among players over time. 

\section{Game meta-heuristics}

\subsection{Learning on previous game-databases}

Learning through pattern-weights (see SHA08):

  Idea: Adapt generic initial strategy by performing 
        self-play, temporal difference method

Reinforcement learning:

  Idea: Represent the environment and use a stochastic
        transition model contingent on other players
        moves (could try to fill in gaps of knowledge 
        with a characterization of other players)

\subsection{Genetic -- adapting parameter vector}

\subsection{bonus, bonus: sentiment analysis of free-form player text}

% All additional bits about agile software development 
%
% including incremenetal development, testing strategies,
% documentation (basically re-state from 1st report to round
% off the report)

\section{Project management}

\subsubsection{Software Engineering Process}
\begin{itemize}
\item Currently an agile software development model is still being followed,
specifically the team development still is much like the Scrum model
\item Sprints i.e. 2 week iterations are planned so that at the end of each
sprint a deliverable can be presented to the Product Owner (i.e. our
supervisor)
\item The next iteration is weeks 5-6 followed by the final iteration which
is weeks 7-8. Week 9 will be allocated as a buffer week to complete
anything that was not completed in the final iteration/sprint
\item There are multiple meetings during a week which enables the team to
get together to discuss current progress and any problems encountered
so far
\item There is also a meeting after each iteration to discuss how the current
iteration/sprint went and if any goals/aims need to be readjusted
for the following iteration
\end{itemize}


\subsection{Team collaboration}

\begin{itemize}
\item Working in a team means that people have different skills and therefore
may end up contributing more than others, but this can be a positive
as the most effective way to work as a team is to use everyone's skills
effectively
\item The two main languages used are Haskell and Haxe. There is one member
who is strongest at Haskell and one who is strongest at Haxe

\begin{itemize}
\item This has meant that for the first two iterations, the two members
mentioned above have led the project and contributed the most
\item However for the next 2 iterations, contributions should be more even
as the rest of the group has had time to learn the languages required
and can make a greater contribution
\end{itemize}
\end{itemize}

\section{Ethical and Environment Impact}

\subsection{Ethical impact}

Users who register for a game on the system may be required to leave
their email addresses and names for authentication. This means their
personal details need to be stored safely and ensure that it is stored
safely and away from any possible attacks on the server. In addition
this personal information needs to be handled with care and that it
is never given out under any circumstances.\\
In order to avoid any ethical issues we would have to ensure that
only team members have access to the database holding this information
and perhaps we would need some sort of encryption on the table itself.

\subsection{Environmental Impact }

A lot of the evaluation work will consist of running experimental
games between the different bots / human players to assess their 
strengths and weaknesses. To conserve computing resources in the 
department we will run the game server and all AI bots on the same
machine concurrently. 

With respect to exploratory reading we discovered that printing
out all background material and having all logbooks on paper is wasteful
and inefficient. On the one hand discussions pertaining to the
whole project are better placed on the central GitHub repository, since 
distribution is straightforward. 

% Need to add some stuff here!

\end{document}
